import os
import time
import numpy as np
import pandas as pd
from flask import Flask, request, jsonify, render_template_string, redirect, url_for
from keras.models import load_model
import joblib
from collections import Counter
from tienxuly import create_input_processor

#==============================================================================
# C·∫§U H√åNH H·ªÜ TH·ªêNG
#==============================================================================

# ƒê·ªãnh nghƒ©a c√°c model s·∫Ω s·ª≠ d·ª•ng
MODELS = {
    "cnn": {
        "path": "models/cnn.h5",           # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file model
        "display_name": "CNN"              # T√™n hi·ªÉn th·ªã
    },
    "logistic": {
        "path": "models/logistic_regressor_multi.h5",
        "display_name": "Logistic Regression"
    },
    "lstm": {
        "path": "models/lstm.h5",
        "display_name": "LSTM"
    }
}

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn scaler
SCALER_PATH = "models/scaler.pkl"

# Th∆∞ m·ª•c l∆∞u files t·∫£i l√™n
UPLOAD_FOLDER = "uploads"

# Mapping m√£ lo·∫°i t·∫•n c√¥ng sang t√™n d·ªÖ ƒë·ªçc
ATTACK_TYPES = {
    0: "Normal",            # Kh√¥ng ph·∫£i t·∫•n c√¥ng
    1: "DoS",               # Denial of Service
    2: "Probe",             # Scan/Probe
    3: "R2L",               # Remote to Local
    4: "U2R",               # User to Root
    5: "Backdoor",          # Backdoor attacks
    6: "Exploits",          # C√°c cu·ªôc t·∫•n c√¥ng khai th√°c l·ªó h·ªïng
    7: "Analysis",          # T·∫•n c√¥ng ph√¢n t√≠ch
    8: "Fuzzers",           # T·∫•n c√¥ng fuzzing
    9: "Worms",             # Virus worm
    10: "Shellcode",        # T·∫•n c√¥ng shellcode
    11: "Generic"           # T·∫•n c√¥ng chung
}

# T·∫°o th∆∞ m·ª•c uploads n·∫øu ch∆∞a t·ªìn t·∫°i
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

#==============================================================================
# T·∫¢I M√î H√åNH V√Ä SCALER
#==============================================================================

print("üîÑ ƒêang load models v√† scaler...")
loaded_models = {}

# V√≤ng l·∫∑p qua t·∫•t c·∫£ model ƒë√£ ƒë·ªãnh nghƒ©a
for model_key, model_info in MODELS.items():
    model_path = model_info["path"]
    
    # Ki·ªÉm tra file model c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(model_path):
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y model {model_key} t·∫°i {model_path}, s·∫Ω b·ªè qua")
        continue
    
    try:
        # Th·ª≠ load model b·∫±ng Keras
        loaded_models[model_key] = load_model(model_path, compile=False)
        print(f"‚úÖ ƒê√£ load th√†nh c√¥ng model {model_key}")
    except Exception as e:
        # X·ª≠ l√Ω l·ªói khi load model
        print(f"‚ùå L·ªói khi load model {model_key}: {str(e)}")

# Ki·ªÉm tra xem c√≥ model n√†o ƒë∆∞·ª£c load th√†nh c√¥ng kh√¥ng
if not loaded_models:
    raise ValueError("Kh√¥ng load ƒë∆∞·ª£c model n√†o, kh√¥ng th·ªÉ ti·∫øp t·ª•c")

# Ki·ªÉm tra file scaler
if not os.path.exists(SCALER_PATH):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y scaler t·∫°i {SCALER_PATH}")

# Load scaler
scaler = joblib.load(SCALER_PATH)
print("‚úÖ ƒê√£ load xong models v√† scaler")

# T·∫°o b·ªô x·ª≠ l√Ω ƒë·∫ßu v√†o
input_processor = create_input_processor()
print("‚úÖ ƒê√£ kh·ªüi t·∫°o b·ªô x·ª≠ l√Ω ƒë·∫ßu v√†o")

#==============================================================================
# KH·ªûI T·∫†O FLASK
#==============================================================================

app = Flask(__name__)
app.config["UPLOAD_FOLDER"] = UPLOAD_FOLDER

# Bi·∫øn l∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch g·∫ßn nh·∫•t
last_prediction = {
    "timestamp": None,                      # Th·ªùi gian ph√¢n t√≠ch
    "total_records": 0,                     # T·ªïng s·ªë b·∫£n ghi ƒë√£ ph√¢n t√≠ch
    "models_results": {},                   # K·∫øt qu·∫£ t·ª´ng model
    "ensemble_result": {                    # K·∫øt qu·∫£ t·ªïng h·ª£p
        "attack_percentage": 0.0,
        "attack_count": 0,
        "normal_count": 0,
        "attack_types": {}
    },
    "preprocessing_info": {}                # Th√¥ng tin ti·ªÅn x·ª≠ l√Ω
}

#==============================================================================
# C√ÅC H√ÄM CH·ª®C NƒÇNG
#==============================================================================

def format_analysis_time(seconds):
    """
    ƒê·ªãnh d·∫°ng th·ªùi gian ph√¢n t√≠ch th√†nh d·∫°ng d·ªÖ ƒë·ªçc
    
    Parameters:
    -----------
    seconds : float
        Th·ªùi gian t√≠nh b·∫±ng gi√¢y
        
    Returns:
    --------
    str
        Chu·ªói th·ªùi gian ƒë·ªãnh d·∫°ng (v√≠ d·ª•: "1d 2h 31' 45''")
    """
    if seconds < 0:
        return "0''"
    
    # T√≠nh to√°n c√°c ƒë∆°n v·ªã th·ªùi gian
    days = int(seconds // 86400)        # 1 ng√†y = 86400 gi√¢y
    hours = int((seconds % 86400) // 3600)  # 1 gi·ªù = 3600 gi√¢y
    minutes = int((seconds % 3600) // 60)   # 1 ph√∫t = 60 gi√¢y
    secs = int(seconds % 60)                # Gi√¢y c√≤n l·∫°i
    
    # T·∫°o chu·ªói k·∫øt qu·∫£
    parts = []
    
    if days > 0:
        parts.append(f"{days}d")
    if hours > 0:
        parts.append(f"{hours}h")
    if minutes > 0:
        parts.append(f"{minutes}'")
    if secs > 0 or len(parts) == 0:  # Lu√¥n hi·ªÉn th·ªã gi√¢y n·∫øu kh√¥ng c√≥ ƒë∆°n v·ªã n√†o kh√°c
        parts.append(f"{secs}''")
    
    return " ".join(parts)

def detect_attack_with_model(X_input, model_key):
    """
    Ph√°t hi·ªán t·∫•n c√¥ng v·ªõi m·ªôt model c·ª• th·ªÉ
    
    Parameters:
    -----------
    X_input : numpy.ndarray
        D·ªØ li·ªáu ƒë·∫ßu v√†o c·∫ßn ph√¢n t√≠ch
    model_key : str
        T√™n model s·∫Ω d√πng ƒë·ªÉ ph√¢n t√≠ch
        
    Returns:
    --------
    predicted_labels : numpy.ndarray
        Nh√£n d·ª± ƒëo√°n cho m·ªói m·∫´u ƒë·∫ßu v√†o
    confidences : numpy.ndarray
        ƒê·ªô tin c·∫≠y c·ªßa c√°c d·ª± ƒëo√°n
    """
    model = loaded_models[model_key]
    # Scale d·ªØ li·ªáu ƒë·∫ßu v√†o ƒë·ªÉ ph√π h·ª£p v·ªõi ph√¢n ph·ªëi c·ªßa t·∫≠p hu·∫•n luy·ªán
    X_scaled = scaler.transform(X_input)
    
    #------------------------------------------------------------------------------
    # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho t·ª´ng lo·∫°i model
    #------------------------------------------------------------------------------
    if model_key == "lstm":
        # LSTM c·∫ßn d·ªØ li·ªáu d·∫°ng sequence (timestep, features)
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng features
        expected_features = model.input_shape[-1]
        
        # ƒêi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng features n·∫øu c·∫ßn
        if X_scaled.shape[1] != expected_features:
            if X_scaled.shape[1] > expected_features:
                print(f"‚ö†Ô∏è S·ªë features ({X_scaled.shape[1]}) nhi·ªÅu h∆°n y√™u c·∫ßu c·ªßa LSTM ({expected_features}), s·∫Ω c·∫Øt b·ªõt")
                X_scaled = X_scaled[:, :expected_features]  # Ch·ªâ l·∫•y s·ªë l∆∞·ª£ng features c·∫ßn thi·∫øt
            else:
                # Tr∆∞·ªùng h·ª£p d·ªØ li·ªáu c√≥ √≠t features h∆°n c·∫ßn thi·∫øt
                print(f"‚ö†Ô∏è S·ªë features ({X_scaled.shape[1]}) √≠t h∆°n y√™u c·∫ßu c·ªßa LSTM ({expected_features}), s·∫Ω th√™m features gi·∫£")
                padding = np.zeros((X_scaled.shape[0], expected_features - X_scaled.shape[1]))
                X_scaled = np.hstack([X_scaled, padding])
        
        # Th√™m chi·ªÅu timestep cho LSTM
        X_scaled = np.expand_dims(X_scaled, axis=1)
        
    elif model_key == "cnn":
        # CNN c·∫ßn d·ªØ li·ªáu d·∫°ng ·∫£nh (samples, height, width, channels)
        # L·∫•y th√¥ng tin input shape t·ª´ model
        input_shape = model.input_shape
        
        # ƒê·∫£m b·∫£o ƒë√¢y l√† m√¥ h√¨nh CNN
        if len(input_shape) == 4:
            expected_features = input_shape[1] * input_shape[2]  # height * width
            
            # ƒêi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng features n·∫øu c·∫ßn
            if X_scaled.shape[1] != expected_features:
                if X_scaled.shape[1] > expected_features:
                    print(f"‚ö†Ô∏è S·ªë features ({X_scaled.shape[1]}) nhi·ªÅu h∆°n y√™u c·∫ßu c·ªßa CNN ({expected_features}), s·∫Ω c·∫Øt b·ªõt")
                    X_scaled = X_scaled[:, :expected_features]
                else:
                    print(f"‚ö†Ô∏è S·ªë features ({X_scaled.shape[1]}) √≠t h∆°n y√™u c·∫ßu c·ªßa CNN ({expected_features}), s·∫Ω th√™m features gi·∫£")
                    padding = np.zeros((X_scaled.shape[0], expected_features - X_scaled.shape[1]))
                    X_scaled = np.hstack([X_scaled, padding])
            
            # Reshape th√†nh d·∫°ng ·∫£nh 2D + k√™nh
            X_scaled = X_scaled.reshape(-1, input_shape[1], input_shape[2], 1)
        else:
            # N·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c shape, s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p m·∫∑c ƒë·ªãnh
            X_scaled = np.expand_dims(X_scaled, axis=-1)
            
    elif model_key == "logistic":
        # Logistic Regression c√≥ th·ªÉ l√† model Keras ho·∫∑c model scikit-learn
        # Ki·ªÉm tra lo·∫°i model v√† x·ª≠ l√Ω ph√π h·ª£p
        if hasattr(model, 'input_shape'):  # Keras model
            expected_features = model.input_shape[1]
            
            # ƒêi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng features n·∫øu c·∫ßn
            if X_scaled.shape[1] != expected_features:
                if X_scaled.shape[1] > expected_features:
                    print(f"‚ö†Ô∏è S·ªë features ({X_scaled.shape[1]}) nhi·ªÅu h∆°n y√™u c·∫ßu c·ªßa Logistic ({expected_features}), s·∫Ω c·∫Øt b·ªõt")
                    X_scaled = X_scaled[:, :expected_features]
                else:
                    print(f"‚ö†Ô∏è S·ªë features ({X_scaled.shape[1]}) √≠t h∆°n y√™u c·∫ßu c·ªßa Logistic ({expected_features}), s·∫Ω th√™m features gi·∫£")
                    padding = np.zeros((X_scaled.shape[0], expected_features - X_scaled.shape[1]))
                    X_scaled = np.hstack([X_scaled, padding])
        else:
            # Gi·∫£ s·ª≠ ƒë√¢y l√† scikit-learn model, kh√¥ng c·∫ßn x·ª≠ l√Ω ƒë·∫∑c bi·ªát
            pass
    
    #------------------------------------------------------------------------------
    # D·ª± ƒëo√°n d·ª±a tr√™n lo·∫°i model
    #------------------------------------------------------------------------------
    if model_key == "logistic" and not hasattr(model, 'predict_proba'):
        # ƒê√¢y l√† model Keras Logistic
        preds = model.predict(X_scaled)
        predicted_labels = np.argmax(preds, axis=1)
        confidences = np.max(preds, axis=1)
    elif model_key == "logistic":
        # ƒê√¢y l√† scikit-learn Logistic Regression model
        predicted_labels = model.predict(X_scaled)
        try:
            # C·ªë g·∫Øng l·∫•y confidence scores n·∫øu c√≥
            probs = model.predict_proba(X_scaled)
            confidences = np.array([probs[i, label] for i, label in enumerate(predicted_labels)])
        except:
            # N·∫øu kh√¥ng c√≥ predict_proba, g√°n confidence = 1
            confidences = np.ones(len(predicted_labels))
    else:
        # D·ª± ƒëo√°n cho c√°c model kh√°c (CNN, LSTM)
        preds = model.predict(X_scaled)
        predicted_labels = np.argmax(preds, axis=1)
        confidences = np.max(preds, axis=1)
    
    return predicted_labels, confidences

#==============================================================================
# ROUTES FLASK
#==============================================================================

@app.route("/")
def home():
    """Trang ch·ªß - Hi·ªÉn th·ªã form upload v√† k·∫øt qu·∫£ ph√¢n t√≠ch n·∫øu c√≥"""
    return render_template_string("""
    <html>
    <head>
        <title>IDS Multi-model Analysis</title>
        <style>
            body { font-family: Arial; padding: 20px; max-width: 900px; margin: 0 auto; }
            .result-box { background-color: #f5f5f5; padding: 15px; border-radius: 5px; margin-top: 20px; }
            .attack-high { color: #d32f2f; font-weight: bold; }
            .attack-medium { color: #f57c00; font-weight: bold; }
            .attack-low { color: #388e3c; font-weight: bold; }
            table { width: 100%; border-collapse: collapse; margin-top: 10px; }
            table, th, td { border: 1px solid #ddd; }
            th, td { padding: 8px; text-align: left; }
            th { background-color: #f2f2f2; }
            .model-section { border-left: 4px solid #2196F3; padding-left: 10px; margin: 15px 0; }
            .model-title { color: #2196F3; margin-bottom: 10px; }
            .ensemble-section { border-left: 4px solid #4CAF50; padding-left: 10px; margin: 15px 0; }
            .ensemble-title { color: #4CAF50; margin-bottom: 10px; }
            .preprocessing-section { border-left: 4px solid #FF9800; padding-left: 10px; margin: 15px 0; }
            .preprocessing-title { color: #FF9800; margin-bottom: 10px; }
            .warning { color: #f44336; }
            .badge { display: inline-block; padding: 0.25em 0.6em; border-radius: 10rem; font-size: 75%; font-weight: 700; }
            .badge-info { background-color: #17a2b8; color: white; }
            .badge-warning { background-color: #ffc107; color: black; }
            .dataset-name { font-weight: bold; font-size: 1.1em; color: #333; background-color: #e3f2fd; padding: 5px 10px; border-radius: 4px; display: inline-block; margin-bottom: 10px; }
        </style>
    </head>
    <body>
        <h2>üõ°Ô∏è IDS Multi-model Analysis</h2>

        <hr>
        <h3>üìÅ Upload file ƒë·ªÉ ph√¢n t√≠ch</h3>
        <form action="/api/upload" method="post" enctype="multipart/form-data">
            <input type="file" name="file" required>
            <input type="submit" value="Ph√¢n t√≠ch">
        </form>
        <p><small>H·ªó tr·ª£ nhi·ªÅu lo·∫°i d·ªØ li·ªáu: CSV, log, PCAP, JSON, XML, Excel, ...</small></p>

        {% if timestamp %}
        <div class="result-box">
            <h3>K·∫øt qu·∫£ ph√¢n t√≠ch</h3>
            <p><strong>Th·ªùi gian:</strong> {{ timestamp }}</p>
            <p><strong>T·∫≠p d·ªØ li·ªáu:</strong> <span class="dataset-name">{{ dataset_name }}</span></p>
            <p><strong>T·ªïng s·ªë b·∫£n ghi:</strong> {{ total_records }}</p>
            
            <!-- K·∫øt qu·∫£ c·ªßa t·ª´ng model -->
            {% for model_key, result in models_results.items() %}
            <div class="model-section">
                <h4 class="model-title">{{ result.display_name }}</h4>
                <p>
                    <strong>T·ªâ l·ªá t·∫•n c√¥ng:</strong> 
                    <span class="{{ 'attack-high' if result.attack_percentage > 30 else 'attack-medium' if result.attack_percentage > 10 else 'attack-low' }}">
                        {{ result.attack_percentage|round(2) }}%
                    </span>
                </p>
                <p><strong>S·ªë b·∫£n ghi th√¥ng th∆∞·ªùng:</strong> {{ result.normal_count }} ({{ (result.normal_count/total_records*100)|round(2) }}%)</p>
                <p><strong>S·ªë b·∫£n ghi t·∫•n c√¥ng:</strong> {{ result.attack_count }} ({{ (result.attack_count/total_records*100)|round(2) }}%)</p>
                <p><strong>‚è±Ô∏è Th·ªùi gian ph√¢n t√≠ch:</strong> {{ result.analysis_time }}</p>
                
                {% if result.attack_types %}
                <h5>Chi ti·∫øt lo·∫°i t·∫•n c√¥ng:</h5>
                <table>
                    <tr>
                        <th>Lo·∫°i t·∫•n c√¥ng</th>
                        <th>S·ªë l∆∞·ª£ng</th>
                        <th>T·ªâ l·ªá (%)</th>
                    </tr>
                    {% for attack_type, count in result.attack_types.items() %}
                    <tr>
                        <td>{{ attack_type }}</td>
                        <td>{{ count }}</td>
                        <td>{{ (count/total_records*100)|round(2) }}%</td>
                    </tr>
                    {% endfor %}
                </table>
                {% endif %}
            </div>
            {% endfor %}
            
        </div>
        {% endif %}
    </body>
    </html>
    """, **last_prediction)

@app.route("/api/predict", methods=["GET"])
def api_predict():
    """API endpoint cho d·ª± ƒëo√°n realtime (hi·ªán t·∫°i ƒë√£ t·∫Øt)"""
    # T·∫°m th·ªùi t·∫Øt ch·ª©c nƒÉng realtime
    return jsonify({"status": "error", "message": "Ch·ª©c nƒÉng realtime t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng."})

@app.route("/api/upload", methods=["POST"])
def upload_and_predict():
    """
    API endpoint x·ª≠ l√Ω file upload v√† th·ª±c hi·ªán ph√¢n t√≠ch
    
    Quy tr√¨nh:
    1. Nh·∫≠n file t·ª´ client
    2. L∆∞u file v√†o th∆∞ m·ª•c upload
    3. X·ª≠ l√Ω file v·ªõi IDSPreprocessor
    4. Ph√¢n t√≠ch v·ªõi t·ª´ng model
    5. T·ªïng h·ª£p k·∫øt qu·∫£ v√† hi·ªÉn th·ªã
    """
    global last_prediction
    
    # Ki·ªÉm tra c√≥ file trong request kh√¥ng
    if "file" not in request.files:
        return jsonify({"status": "error", "message": "Kh√¥ng t√¨m th·∫•y file trong y√™u c·∫ßu."})
    
    file = request.files["file"]
    if file.filename == "":
        return jsonify({"status": "error", "message": "File kh√¥ng h·ª£p l·ªá."})
    
    try:
        # L∆∞u file upload v√†o th∆∞ m·ª•c t·∫°m
        filepath = os.path.join(app.config["UPLOAD_FOLDER"], file.filename)
        file.save(filepath)
        print(f"‚úÖ ƒê√£ l∆∞u file t·∫°i: {filepath}")

        #----------------------------------------------------------------------
        # B∆Ø·ªöC 1: TI·ªÄN X·ª¨ L√ù FILE
        #----------------------------------------------------------------------
        print(f"üîÑ ƒêang ti·ªÅn x·ª≠ l√Ω file {file.filename}...")
        try:
            # G·ªçi processor ƒë·ªÉ x·ª≠ l√Ω file ƒë·∫ßu v√†o
            df, preprocessing_info = input_processor.process_file(filepath)
            print(f"‚úÖ Ti·ªÅn x·ª≠ l√Ω ho√†n t·∫•t: {len(df)} b·∫£n ghi v·ªõi {df.shape[1]} features")
        except Exception as e:
            print(f"‚ùå L·ªói khi ti·ªÅn x·ª≠ l√Ω: {str(e)}")
            return jsonify({"status": "error", "message": f"L·ªói khi ti·ªÅn x·ª≠ l√Ω: {str(e)}"})
        
        #----------------------------------------------------------------------
        # B∆Ø·ªöC 2: PH√ÇN T√çCH V·ªöI T·ª™NG MODEL
        #----------------------------------------------------------------------
        models_results = {}                  # L∆∞u k·∫øt qu·∫£ t·ª´ng model
        all_predictions = {}                 # L∆∞u d·ª± ƒëo√°n ƒë·ªÉ ensemble
        
        # Ph√¢n t√≠ch v·ªõi t·ª´ng model
        for model_key, model_info in MODELS.items():
            # B·ªè qua models kh√¥ng load ƒë∆∞·ª£c
            if model_key not in loaded_models:
                continue
                
            print(f"üîç ƒêang ph√¢n t√≠ch v·ªõi model {model_key}...")
            
            try:
                # ƒêo th·ªùi gian b·∫Øt ƒë·∫ßu
                model_start_time = time.time()

                # X·ª≠ l√Ω theo batch n·∫øu d·ªØ li·ªáu l·ªõn
                BATCH_SIZE = 1000
                all_labels = []              # L∆∞u nh√£n d·ª± ƒëo√°n
                all_confidences = []         # L∆∞u ƒë·ªô tin c·∫≠y
                
                # X·ª≠ l√Ω t·ª´ng batch ƒë·ªÉ tr√°nh qu√° t·∫£i b·ªô nh·ªõ
                for i in range(0, len(df), BATCH_SIZE):
                    batch = df.iloc[i:i+BATCH_SIZE].values
                    batch_labels, batch_confidences = detect_attack_with_model(batch, model_key)
                    all_labels.extend(batch_labels)
                    all_confidences.extend(batch_confidences)
                
                # ƒêo th·ªùi gian k·∫øt th√∫c
                model_end_time = time.time()
                analysis_time_seconds = model_end_time - model_start_time
                analysis_time_formatted = format_analysis_time(analysis_time_seconds)

                # L∆∞u t·∫•t c·∫£ d·ª± ƒëo√°n cho ensemble
                all_predictions[model_key] = all_labels
                
                #--------------------------------------------------------------
                # B∆Ø·ªöC 3: PH√ÇN T√çCH K·∫æT QU·∫¢ CHO MODEL
                #--------------------------------------------------------------
                # ƒê·∫øm s·ªë l∆∞·ª£ng m·∫´u t·∫•n c√¥ng v√† m·∫´u b√¨nh th∆∞·ªùng
                attack_count = sum(1 for label in all_labels if label != 0)
                normal_count = len(all_labels) - attack_count
                attack_percentage = (attack_count / len(all_labels)) * 100 if len(all_labels) > 0 else 0
                
                # ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i t·∫•n c√¥ng
                attack_types_counter = Counter(all_labels)
                attack_types = {}
                
                # S·ª≠ d·ª•ng t√™n t·∫•n c√¥ng t·ª´ mapping
                for attack_id, count in attack_types_counter.items():
                    if attack_id != 0:  # B·ªè qua normal (0)
                        attack_name = ATTACK_TYPES.get(attack_id, f"Lo·∫°i kh√¥ng x√°c ƒë·ªãnh ({attack_id})")
                        attack_types[attack_name] = count
                
                # S·∫Øp x·∫øp theo s·ªë l∆∞·ª£ng gi·∫£m d·∫ßn
                attack_types = dict(sorted(attack_types.items(), key=lambda x: x[1], reverse=True))
                
                # L∆∞u k·∫øt qu·∫£ c·ªßa model hi·ªán t·∫°i
                models_results[model_key] = {
                    "display_name": model_info["display_name"],
                    "attack_percentage": attack_percentage,
                    "attack_count": attack_count,
                    "normal_count": normal_count,
                    "attack_types": attack_types,
                    "analysis_time": analysis_time_formatted,    # Th·ªùi gian ƒë·ªãnh d·∫°ng
                    "analysis_time_raw": analysis_time_seconds   # Th·ªùi gian th√¥ (gi√¢y) ƒë·ªÉ s·ª≠ d·ª•ng trong t√≠nh to√°n kh√°c
                }
                
                print(f"‚úÖ Ho√†n th√†nh ph√¢n t√≠ch v·ªõi {model_key} trong {analysis_time_formatted}")
                
            except Exception as e:
                # Ghi nh·∫≠n l·ªói v√† b·ªè qua model n√†y
                print(f"‚ùå L·ªói khi ph√¢n t√≠ch v·ªõi model {model_key}: {str(e)}")
                continue

        # Ki·ªÉm tra c√≥ model n√†o cho k·∫øt qu·∫£ kh√¥ng
        if not models_results:
            return jsonify({"status": "error", "message": "Kh√¥ng th·ªÉ ph√¢n t√≠ch v·ªõi b·∫•t k·ª≥ model n√†o."})
        
        #----------------------------------------------------------------------
        # B∆Ø·ªöC 4: T·∫†O K·∫æT QU·∫¢ ENSEMBLE B·∫∞NG PH∆Ø∆†NG PH√ÅP VOTING
        #----------------------------------------------------------------------
        ensemble_predictions = []
        
        # Voting cho t·ª´ng m·∫´u
        for i in range(len(df)):
            votes = []
            for model_key in all_predictions:
                if i < len(all_predictions[model_key]):
                    votes.append(all_predictions[model_key][i])
            
            if votes:
                # L·∫•y k·∫øt qu·∫£ ph·ªï bi·∫øn nh·∫•t (majority voting)
                most_common = Counter(votes).most_common(1)[0][0]
                ensemble_predictions.append(most_common)
        
        # T√≠nh to√°n k·∫øt qu·∫£ ensemble
        ensemble_attack_count = sum(1 for label in ensemble_predictions if label != 0)
        ensemble_normal_count = len(ensemble_predictions) - ensemble_attack_count
        ensemble_attack_percentage = (ensemble_attack_count / len(ensemble_predictions)) * 100 if ensemble_predictions else 0
        
        # ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i t·∫•n c√¥ng cho ensemble
        ensemble_attack_types_counter = Counter(ensemble_predictions)
        ensemble_attack_types = {}
        
        for attack_id, count in ensemble_attack_types_counter.items():
            if attack_id != 0:  # B·ªè qua normal (0)
                attack_name = ATTACK_TYPES.get(attack_id, f"Lo·∫°i kh√¥ng x√°c ƒë·ªãnh ({attack_id})")
                ensemble_attack_types[attack_name] = count
        
        # S·∫Øp x·∫øp theo s·ªë l∆∞·ª£ng gi·∫£m d·∫ßn
        ensemble_attack_types = dict(sorted(ensemble_attack_types.items(), key=lambda x: x[1], reverse=True))
        
        #----------------------------------------------------------------------
        # B∆Ø·ªöC 5: CHU·∫®N B·ªä K·∫æT QU·∫¢ CU·ªêI C√ôNG
        #----------------------------------------------------------------------
        last_prediction = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),  # Th·ªùi gian ph√¢n t√≠ch
            "total_records": len(df),                         # T·ªïng s·ªë b·∫£n ghi
            "models_results": models_results,                 # K·∫øt qu·∫£ t·ª´ng model
            "ensemble_result": {                              # K·∫øt qu·∫£ ensemble
                "attack_percentage": ensemble_attack_percentage,
                "attack_count": ensemble_attack_count,
                "normal_count": ensemble_normal_count,
                "attack_types": ensemble_attack_types
            },
            "preprocessing_info": preprocessing_info,         # Th√¥ng tin ti·ªÅn x·ª≠ l√Ω
            "dataset_name": file.filename                     # T√™n t·∫≠p d·ªØ li·ªáu
        }
        
        print(f"‚úÖ ƒê√£ ho√†n th√†nh ph√¢n t√≠ch v·ªõi {len(models_results)} models")

        # Redirect v·ªÅ trang ch·ªß ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£
        return redirect(url_for("home"))

    except Exception as e:
        # X·ª≠ l√Ω ngo·∫°i l·ªá kh√¥ng l∆∞·ªùng tr∆∞·ªõc
        print(f"‚ùå L·ªói: {str(e)}")
        return jsonify({"status": "error", "message": str(e)})

#==============================================================================
# CH·∫†Y ·ª®NG D·ª§NG
#==============================================================================

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
